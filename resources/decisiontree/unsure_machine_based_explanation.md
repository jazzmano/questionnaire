If you are unsure whether your systemÂ infer, from the input it receives, how to generate outputs, you have two choices:

1. **Assume it does infer how to generate outputs (recommended).**

2. \**Assume it does *not\* infer how to generate outputs.

We recommend you assume it _does_.

**Why?**  
AI systems must be able to figure out how to turn inputs into outputs. 'Inference' can be thought of as the AI systems ability to think. This inference capability can be present both when the AI system is being _developed_ and when it is being _used_.

During the **development phase**, an AI system can figure out algorithms or models from the data it is trained on. Think of it as the AI system getting a recipe of how the world works based on the training data it sees.

During the use phase, an AI system must be able to figure out what to do with the inputs it receives. If you use an AI-system like ChatGPT, your prompt is your input, and ChatGPT must then figure out what to do with it. _That_ is inference.

**Consideration - for and against**
If you assume that your system is able to infer, from the input it receives, how to generate outputs, it might be covered by the AI Act, but if your system is not prohibited or high-risk, the rules you need to follow are usually simple. Therefore, this approach makes sure you are on the safe side, as you do not miss anything.

If you wrongly assume that your system does not infer, from the input it receives, how to generate outputs, and the system is subject to the AI Act, you could unknowingly break the law, which could lead to fines or other penalties.

**When in doubt, assume your system is able to infer, from the input it receives, how to generate outputs.**  
Better safe than sorry.

