If you are unsure whether your systemÂ is designed to operate according to one or more implicit or explicit objectives, you have two choices:

1. **Assume it does operate according to one or more implicit or explicit objectives (recommended).**

2. **Assume it does operate according to one or more implicit or explicit objectives.

We recommend you assume it *does*.

**Why?**  
AI systems are designed to operate according to one or more objectives, meaning it must not operate at random. The objectives of the system may be explicitly or implicitly defined. 

Explicit objectives refer to clearly stated goals that are directly encoded by the developer into the system. For example, they may be specified as the optimisation of some cost function, a probability, or a cumulative reward. 

Implicit objectives refer to goals that are not explicitly stated but may be deduced from the behaviour or underlying assumptions of the system. These objectives may arise from the training data or from the interaction of the AI system with its environment.

Unless your system operates completely at random, it will operate according to one or more implicit or explicit objectives. 

If you assume that your system operate according to one or more implicit or explicit objectives, it might be covered by the AI Act, but if your system is not prohibited or high-risk, the rules you need to follow are usually simple. Therefore, this approach makes sure you are on the safe side, as you do not miss anything. 

If you wrongly assume that your system is does not operate according to one or more implicit or explicit objectives, and the system is subject to the AI Act, you could unknowingly break the law, which could lead to fines or other penalties.

**When in doubt, assume your system operate according to one or more implicit or explicit objectives.**  
Better safe than sorry.
