If you are unsure whether your system operates with a level of autonomy, you have two choices:

1. **Option 1: Assume it *does* operate with a level of autonomy .**

2. **Option 2: Assume it does *not* operate with a level of autonomy.**

We recommend you assume it *does* (option 1).

**Why?**  
*Why choose option 1?*
To be considered an AI system under the AI Act, your system must operate with some degree of autonomy, meaning it can perform tasks or generate outputs without constant human control. But the threshold for autonomy is very low. Even small steps performed independently by the system can qualify. For example, a simple spam filter that automatically classifies emails as spam already meets this condition.

If you assume that your system has autonomy, it might fall under the AI Act (if the other legal conditions are also met). However, if your system is not prohibited or high-risk, the applicable rules are generally straightforward. By assuming autonomy, you ensure that you do not overlook any legal obligations. This helps keep your compliance position safe.

Autonomy introduces potential risks if left unmanaged. By assuming your system has a level of autonomy, you establish the need for appropriate human oversight thereby helping to mitigate risks of the system acting independently in ways you did not intend. Even if your system is ultimately not autonomous, building governance procedures can add business value: it promotes accountability, strengthens trust with customers and regulators, and reduces the risk of harmful outcomes. Moreover, systems with oversight can often easier sell into regulated markets, win public tenders, and pass procurement reviews.

*Why choose option 2?*
If you wrongly assume that your system is not autonomous, and it is actually subject to the AI Act, you risk unknowingly infringing on the AI Act, which could result in fines or other penalties. You should therefore only choose option 2 if you are absolutely certain.

In addition, if your system is autonomous but you assume it is not, the business risks can be severe. To give an example, imagine that an airline deploys software that autonomously reroutes flights. Without proper human oversight, even a few poor decisions could cause major disruption, financial loss, or even endanger lives, all because no one recognised the need for human control.

For this reason, if there is any doubt, it is safer to assume that your system has autonomy and apply the necessary oversight and compliance measures.


**When in doubt, assume your system acts with autonomy.** Better safe than sorry.
