If you are unsure whether your system operates with a level of autonomy, you have two choices:

1. **Option 1: Assume it *does* operate with a level of autonomy .**

2. **Option 2: Assume it does *not* operate with a level of autonomy.**

We recommend you assume it *does*.

**Why?**  
*Why choose option 1?*
To be considered an AI system under the AI Act, your system needs to act with *some* independence from humans. But that threshold is *very* low. Even small steps taken without human control count as autonomy. For example, if your system receives input and generates an output on its own, such as a recommendation, it operates with a sufficient level of autonomy. This could be a simple spam filter that decides what e-mails to count as spam.  

If you assume that your system has autonomy, it *might* be covered by the AI Act (if the other conditions for having an AI system are also fulfilled), but if your system is not prohibited or high-risk, the rules you need to follow are usually simple. Therefore, this approach makes sure you are on the safe side, as you do not miss anything. 

Autonomy can be dangerous if left unattended. By assuming your system has a level of autonomy, you know that you need to establish some form of human oversight, thereby minimizing the dangers associated with the system's potential autonomy. 

*Why choose option 2?*
If you wrongly assume that your system is not autonomous, and the system is subject to the AI Act, you could unknowingly break the law, which could lead to fines or other penalties. You should therefore only choose option 2 if you are absolutely sure. 

Additionally, if your system is autonomous but you have assumed it is not, you could be in for a bad surprise. Imagine an airline deploying software that routes and reroutes planes based on weight, weather, and air traffic conditions. If that system operates with some level of autonomy and ends up rerouting hundreds of flights without proper oversight, even a few poor decisions could cause serious disruption, such as delays, financial losses, or even death. All because no one realized the system was autonomous and therefore in need of a human in the loop.

**When in doubt, assume your system acts with autonomy.** Better safe than sorry.
