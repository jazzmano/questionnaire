If you are unsure whether your system is able toÂ generate outputs such as predictions, content, recommendations, or decisions, you have two choices:

1. **Assume it is able to generate outputs (recommended).**

2. **Assume it is not able to generate outputs.**

We recommend you assume it *is*.

**Why?**  
As a rule, AI systems can generally generate more nuanced outputs than other systems, for example, by leveraging patterns learned during training or by using expert-defined rules to make decisions, offering more sophisticated reasoning in structured environments.

The ability of a system, to generate outputs, such as predictions, content, and recommendations, based on inputs it
receives and using machine learning and logic and knowledge-based approaches, is fundamental to what AI systems do and what distinguishes those systems from other forms of software.

There are generally four broad categories of outputs: predictions, content, recommendations, and decisions.

*Predictions* are estimates about an unknown value (the output) from known values supplied to the system (the input).

*Content* refers to the generation of new material by an AI system, in other words generative AI. 

*Recommendations* refer to suggestions for specific actions, products, or services to users based on their preferences, behaviours, or other data inputs.

*Decisions* refer to conclusions or choices made by a system.

**Consideration - for and against**
If you assume that your system can generate outputs, it might be covered by the AI Act, but if your system is not prohibited or high-risk, the rules you need to follow are usually simple. Therefore, this approach makes sure you are on the safe side, as you do not miss anything. 

If you wrongly assume that your system is not able to generate outputs, and the system is subject to the AI Act, you could unknowingly break the law, which could lead to fines or other penalties.

**When in doubt, assume your system can generate outputs.**  
Better safe than sorry.
